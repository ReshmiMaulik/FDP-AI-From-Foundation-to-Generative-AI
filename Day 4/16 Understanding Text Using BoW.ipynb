{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edc47ab",
   "metadata": {},
   "source": [
    "# Step 1: Install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3e9157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\shrim\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shrim\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shrim\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\shrim\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\shrim\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1155de",
   "metadata": {},
   "source": [
    "# Step 2: Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef182bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd7c19",
   "metadata": {},
   "source": [
    "# Step 3: Sample Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e3b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "documents = [\n",
    "    \"Bag of Words is a common technique in natural language processing.\",\n",
    "    \"It represents text data as a numerical feature vector.\",\n",
    "    \"Scikit-learn provides a convenient CountVectorizer for implementing Bag of Words.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f0dd8",
   "metadata": {},
   "source": [
    "# Step 4: Create a Bag of Words Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21c3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer instance\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the result to an array for better readability\n",
    "bow_array = X.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd95bcd",
   "metadata": {},
   "source": [
    "# Step 5: Explore the Bag of Words Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8283b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names (Words): ['as' 'bag' 'common' 'convenient' 'countvectorizer' 'data' 'feature' 'for'\n",
      " 'implementing' 'in' 'is' 'it' 'language' 'learn' 'natural' 'numerical'\n",
      " 'of' 'processing' 'provides' 'represents' 'scikit' 'technique' 'text'\n",
      " 'vector' 'words']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "[[0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1]\n",
      " [1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0]\n",
      " [0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Display the feature names (words) in the Bag of Words model\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Feature Names (Words):\", feature_names)\n",
    "\n",
    "# Display the Bag of Words matrix\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "print(bow_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ff0ef",
   "metadata": {},
   "source": [
    "This code demonstrates how to create a Bag of Words model using scikit-learn's CountVectorizer. The resulting matrix (bow_array) represents the frequency of each word in the documents.\n",
    "\n",
    "You can use this Bag of Words representation as input to various machine learning models for text classification, clustering, or other natural language processing tasks.\n",
    "\n",
    "Feel free to replace the sample text data with your own dataset and explore the Bag of Words representation for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da56f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   algorithms  allocation       are  artificial    corpus  dirichlet  \\\n",
      "0    0.000000    0.000000  0.000000    0.420222  0.000000   0.000000   \n",
      "1    0.000000    0.000000  0.000000    0.000000  0.322426   0.000000   \n",
      "2    0.000000    0.000000  0.000000    0.000000  0.000000   0.000000   \n",
      "3    0.000000    0.376149  0.000000    0.000000  0.000000   0.376149   \n",
      "4    0.337214    0.000000  0.337214    0.000000  0.000000   0.000000   \n",
      "\n",
      "        for  identify        in  intelligence  ...     spacy  subfield  \\\n",
      "0  0.000000  0.000000  0.000000      0.420222  ...  0.000000  0.420222   \n",
      "1  0.000000  0.322426  0.322426      0.000000  ...  0.000000  0.000000   \n",
      "2  0.270904  0.000000  0.000000      0.000000  ...  0.404509  0.000000   \n",
      "3  0.251911  0.000000  0.000000      0.000000  ...  0.000000  0.000000   \n",
      "4  0.225836  0.000000  0.000000      0.000000  ...  0.000000  0.000000   \n",
      "\n",
      "      tasks  technique      text        to     topic    topics      used  \\\n",
      "0  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000   0.322426  0.322426  0.322426  0.260131  0.322426  0.000000   \n",
      "2  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.000000   0.000000  0.000000  0.000000  0.303474  0.000000  0.000000   \n",
      "4  0.337214   0.000000  0.000000  0.000000  0.000000  0.000000  0.337214   \n",
      "\n",
      "    various  \n",
      "0  0.000000  \n",
      "1  0.000000  \n",
      "2  0.000000  \n",
      "3  0.000000  \n",
      "4  0.337214  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "    \"Topic modeling is a technique to identify topics present in a text corpus.\",\n",
    "    \"SpaCy is a popular Python library for natural language processing.\",\n",
    "    \"Latent Dirichlet Allocation is a probabilistic model for topic modeling.\",\n",
    "    \"Machine learning algorithms are used for various natural language processing tasks.\",\n",
    "]\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (words) and the TF-IDF matrix\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_matrix_array = tfidf_matrix.toarray()\n",
    "\n",
    "'''\n",
    "\n",
    "# Display the TF-IDF representation\n",
    "print(\"Feature Names (Words):\", feature_names)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix_array)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Convert the TF-IDF matrix to a pandas DataFrame\n",
    "import pandas as pd\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix_array, columns=feature_names)\n",
    "\n",
    "# Display the TF-IDF DataFrame\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6084ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms</th>\n",
       "      <th>allocation</th>\n",
       "      <th>are</th>\n",
       "      <th>artificial</th>\n",
       "      <th>corpus</th>\n",
       "      <th>dirichlet</th>\n",
       "      <th>for</th>\n",
       "      <th>identify</th>\n",
       "      <th>in</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>...</th>\n",
       "      <th>spacy</th>\n",
       "      <th>subfield</th>\n",
       "      <th>tasks</th>\n",
       "      <th>technique</th>\n",
       "      <th>text</th>\n",
       "      <th>to</th>\n",
       "      <th>topic</th>\n",
       "      <th>topics</th>\n",
       "      <th>used</th>\n",
       "      <th>various</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376149</td>\n",
       "      <td>0.251911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.337214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337214</td>\n",
       "      <td>0.337214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithms  allocation       are  artificial    corpus  dirichlet  \\\n",
       "0    0.000000    0.000000  0.000000    0.420222  0.000000   0.000000   \n",
       "1    0.000000    0.000000  0.000000    0.000000  0.322426   0.000000   \n",
       "2    0.000000    0.000000  0.000000    0.000000  0.000000   0.000000   \n",
       "3    0.000000    0.376149  0.000000    0.000000  0.000000   0.376149   \n",
       "4    0.337214    0.000000  0.337214    0.000000  0.000000   0.000000   \n",
       "\n",
       "        for  identify        in  intelligence  ...     spacy  subfield  \\\n",
       "0  0.000000  0.000000  0.000000      0.420222  ...  0.000000  0.420222   \n",
       "1  0.000000  0.322426  0.322426      0.000000  ...  0.000000  0.000000   \n",
       "2  0.270904  0.000000  0.000000      0.000000  ...  0.404509  0.000000   \n",
       "3  0.251911  0.000000  0.000000      0.000000  ...  0.000000  0.000000   \n",
       "4  0.225836  0.000000  0.000000      0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "      tasks  technique      text        to     topic    topics      used  \\\n",
       "0  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000   0.322426  0.322426  0.322426  0.260131  0.322426  0.000000   \n",
       "2  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000   0.000000  0.000000  0.000000  0.303474  0.000000  0.000000   \n",
       "4  0.337214   0.000000  0.000000  0.000000  0.000000  0.000000  0.337214   \n",
       "\n",
       "    various  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.337214  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f5f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
